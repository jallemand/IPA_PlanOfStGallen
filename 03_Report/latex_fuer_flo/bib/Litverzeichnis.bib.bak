% Encoding: UTF-8

@Article{he2015,
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  title         = {Deep Residual Learning for Image Recognition},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1512.03385},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, http://dblp.org},
  biburl        = {http://dblp.org/rec/bib/journals/corr/HeZRS15},
  eprint        = {1512.03385},
  groups        = {ResNet CNN allgemein},
  timestamp     = {Wed, 07 Jun 2017 14:41:17 +0200},
  url           = {http://arxiv.org/abs/1512.03385},
}

@Article{Simonyan2014,
  author        = {Karen Simonyan and Andrew Zisserman},
  title         = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal       = {CoRR},
  year          = {2014},
  volume        = {abs/1409.1556},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, http://dblp.org},
  biburl        = {http://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  eprint        = {1409.1556},
  groups        = {ResNet CNN allgemein},
  timestamp     = {Wed, 07 Jun 2017 14:41:51 +0200},
  url           = {http://arxiv.org/abs/1409.1556},
}

@Article{branson2018,
  author   = {Steve Branson and Jan Dirk Wegner and David Hall and Nico Lang and Konrad Schindler and Pietro Perona},
  title    = {From Google Maps to a fine-grained catalog of street trees},
  journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  year     = {2018},
  volume   = {135},
  pages    = {13 - 30},
  issn     = {0924-2716},
  doi      = {https://doi.org/10.1016/j.isprsjprs.2017.11.008},
  groups   = {Related Work Trees},
  keywords = {Deep learning, Image interpretation, Urban areas, Street trees, Very high resolution},
}

@Article{Wegner2016,
  author = {Wegner, Jan and Branson, Steve and Hall, David and Schindler, Konrad and Perona, Pietro},
  title  = {Cataloging Public Objects Using Aerial and Street-Level Images – Urban Trees},
  year   = {2016},
  month  = {06},
  groups = {Related Work Trees},
}

@Article{Dobbertin2009,
  author  = {Dobbertin, Matthias and Hug, Christian and Waldner, Peter},
  title   = {Kronenverlichtung, Sterberaten und Waldwachstum in Langzeitstudien – Welche Indikatoren beschreiben den Waldzustand am besten?},
  journal = {Forum für Wissen},
  year    = {2009},
  pages   = {7-20},
  groups  = {Forest and Trees},
}

@TechReport{Waldbericht2015,
  author      = {Andreas Riglin and Hans Peter Schaffer},
  title       = {Waldbericht 2015. Zustand und Nutzung des Schweizer Waldes},
  institution = {Bundesamt für Umwelt BAFU, Bern and Eidg. Forschungsanstalt WSL, Birmensdorf},
  year        = {2015},
  groups      = {Forest and Trees},
}

@Article{Mizoue2004,
  author   = {Nobuya Mizoue and Matthias Dobbertin},
  title    = {Within country accuracy of tree crown transparency estimates using the image analysis system CROCO: a case study from Switzerland},
  journal  = {Environmental Modelling \& Software},
  year     = {2004},
  volume   = {19},
  number   = {12},
  pages    = {1089 - 1095},
  issn     = {1364-8152},
  doi      = {https://doi.org/10.1016/j.envsoft.2003.10.009},
  groups   = {Forest and Trees},
  keywords = {Image analysis, Tree condition monitoring, Accuracy, Visual assessment},
  url      = {http://www.sciencedirect.com/science/article/pii/S1364815203002652},
}

@Article{Dobbertin2005,
  author   = {Dobbertin, Matthias and Hug, Christian and Mizoue, Nobuya},
  title    = {Using slides to test for changes in crown defoliation assessment methods part II: Application of the image analysis system CROCO},
  journal  = {Environmental Monitoring and Assessment},
  year     = {2005},
  volume   = {102},
  number   = {1},
  pages    = {167--178},
  issn     = {1573-2959},
  abstract = {We tested whether the semi-automatic program CROCO can replace visual assessments of slides to detect changes in defoliation assessment methods. We randomly selected a series of slides of 24 Norway spruce trees with 220 field assessments made between 1986 and 1995. The slides had been randomly arranged and assessed by three experts without knowledge of the tree number or the year when the slide was taken. Defoliation scores were computed with CROCO. Each tree had thus three different defoliation scores, field assessments, photo assessments and CROCO scores.},
  day      = {01},
  doi      = {10.1007/s10661-005-6019-1},
  groups   = {Forest and Trees},
  url      = {https://doi.org/10.1007/s10661-005-6019-1},
}

@Article{Dobbertin2004,
  author    = {Dobbertin, Matthias and Hug, Christian and Mizoue, Nobuya},
  title     = {Using Slides to Test for Changes in Crown Defoliation Assessment Methods. Part I: Visual Assessment of Slides},
  journal   = {Environmental Monitoring and Assessment},
  year      = {2004},
  volume    = {98},
  pages     = {295-306},
  note      = {https://www.ncbi.nlm.nih.gov/pubmed/15473542},
  abstract  = {In this study we used photographs of tree crowns to test whether the assessment methods for tree defoliation in Switzerland have changed over time. We randomly selected 24 series of slides of Norway spruce with field assessments made between 1986 and 1995. The slides were randomly arranged and assessed by three experts without prior knowledge of the year when the slide was taken or the tree number. Defoliation was assessed using the Swiss reference photo guide. Although the correlations between the field assessments and slide assessments were high (Spearman's rank correlation coefficient ranged between 0.79 and 0.83), we found significant differences between field and slide assessments (4.3 to 9% underprediction by the slide assessors) and between the slide assessments. However, no significant trends in field assessment methods could be detected. When the mean differences between field and slide assessments were subtracted, in some years, field assessors consistently underpredicted (1990, 1992) or overpredicted defoliation (1987, 1991). Defoliation tended to be overpredicted in slides taken against the light, and underpredicted for trees with more than 25% crown overlap. We conclude that slide series can be used to detect changes in assessment methods. However, potential observer bias calls for more objective methods of assessment.},
  booktitle = {Environmental monitoring and assessment},
  groups    = {Forest and Trees},
}

@Article{hochreiter1997,
  author   = {Sepp Hochreiter and Jürgen Schmidhuber},
  title    = {Long Short-Term Memory},
  journal  = {Neural Computation},
  year     = {1997},
  volume   = {9},
  number   = {8},
  pages    = {1735-1780},
  abstract = { Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms. },
  doi      = {10.1162/neco.1997.9.8.1735},
  eprint   = {https://doi.org/10.1162/neco.1997.9.8.1735},
  groups   = {ResNet CNN allgemein},
  url      = { 
        https://doi.org/10.1162/neco.1997.9.8.1735
    
},
}

@InCollection{graves2012,
  author                     = {Graves, A},
  title                      = {{Supervised Sequence Labelling with Recurrent Neural Networks}},
  booktitle                  = {{SUPERVISED SEQUENCE LABELLING WITH RECURRENT NEURAL NETWORKS}},
  publisher                  = {{SPRINGER-VERLAG BERLIN}},
  year                       = {{2012}},
  volume                     = {{385}},
  series                     = {{Studies in Computational Intelligence}},
  type                       = {{Book}},
  pages                      = {{1-141}},
  address                    = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
  isbn                       = {{978-3-642-24797-2}},
  da                         = {{2018-03-12}},
  doc-delivery-number        = {{BAI62}},
  doi                        = {{10.1007/978-3-642-24797-2}},
  groups                     = {ResNet CNN allgemein},
  issn                       = {{1860-949X}},
  keywords-plus              = {{LONG-TERM DEPENDENCIES; HIDDEN MARKOV-MODELS; SPEECH RECOGNITION; HANDWRITING RECOGNITION; PHONEME CLASSIFICATION; BIDIRECTIONAL LSTM; GRADIENT DESCENT; MEMORY; TIME; PERFORMANCE}},
  language                   = {{English}},
  number-of-cited-references = {{157}},
  research-areas             = {{Computer Science}},
  times-cited                = {{136}},
  unique-id                  = {{ISI:000304280700010}},
  usage-count-last-180-days  = {{0}},
  usage-count-since-2013     = {{3}},
  web-of-science-categories  = {{Computer Science, Artificial Intelligence}},
}

@Article{gers2000,
  author                     = {Gers, FA and Schmidhuber, J and Cummins, F},
  title                      = {{Learning to forget: Continual prediction with LSTM}},
  journal                    = {{NEURAL COMPUTATION}},
  year                       = {{2000}},
  volume                     = {{12}},
  number                     = {{10}},
  pages                      = {{2451-2471}},
  issn                       = {{0899-7667}},
  abstract                   = {{Long short-term memory (LSTM; Hochreiter \& Schmidhuber, 1997) can solve
   numerous tasks not solvable by previous learning algorithms for
   recurrent neural networks (RNNs). We identify a weakness of LSTM
   networks processing continual input streams that are not a priori
   segmented into subsequences with explicitly marked ends at which the
   network's internal state could be reset. Without resets, the state may
   grow indefinitely and eventually cause the network to break down. Our
   remedy is a novel, adaptive ``forget gate{''} that enables an LSTM cell
   to learn to reset itself at appropriate times, thus releasing internal
   resources. We review illustrative benchmark problems on which standard
   LSTM outperforms other RNN algorithms. All algorithms (including LSTM)
   fail to solve continual versions of these problems. LSTM with forget
   gates, however, easily solves them, and in an elegant way.}},
  address                    = {{FIVE CAMBRIDGE CENTER, CAMBRIDGE, MA 02142 USA}},
  affiliation                = {{Gers, FA (Reprint Author), IDSIA, CH-6900 Lugano, Switzerland. IDSIA, CH-6900 Lugano, Switzerland.}},
  da                         = {{2018-03-12}},
  doc-delivery-number        = {{356BX}},
  doi                        = {{10.1162/089976600300015015}},
  journal-iso                = {{Neural Comput.}},
  keywords-plus              = {{RECURRENT NEURAL NETWORKS; LONG-TERM DEPENDENCIES}},
  language                   = {{English}},
  number-of-cited-references = {{22}},
  publisher                  = {{M I T PRESS}},
  research-areas             = {{Computer Science; Neurosciences \& Neurology}},
  times-cited                = {{215}},
  type                       = {{Article}},
  unique-id                  = {{ISI:000089425100011}},
  usage-count-last-180-days  = {{19}},
  usage-count-since-2013     = {{46}},
  web-of-science-categories  = {{Computer Science, Artificial Intelligence; Neurosciences}},
}

@Article{Szegedy2015,
  author        = {Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
  title         = {Rethinking the Inception Architecture for Computer Vision},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1512.00567},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/SzegedyVISW15},
  eprint        = {1512.00567},
  groups        = {ResNet CNN allgemein},
  timestamp     = {Wed, 07 Jun 2017 14:40:22 +0200},
  url           = {http://arxiv.org/abs/1512.00567},
}

@Article{Szegedy2013,
  author        = {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian J. Goodfellow and Rob Fergus},
  title         = {Intriguing properties of neural networks},
  journal       = {CoRR},
  year          = {2013},
  volume        = {abs/1312.6199},
  abstract      = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.
First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.
Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input. },
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/SzegedyZSBEGF13},
  eprint        = {1312.6199},
  groups        = {ResNet CNN allgemein},
  timestamp     = {Wed, 07 Jun 2017 14:41:52 +0200},
  url           = {http://arxiv.org/abs/1312.6199},
}

@Article{Szegedy2016,
  author        = {Christian Szegedy and Sergey Ioffe and Vincent Vanhoucke},
  title         = {Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning},
  journal       = {CoRR},
  year          = {2016},
  volume        = {abs/1602.07261},
  abstract      = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the ImageNet classification (CLS) challenge Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the ImageNet classification (CLS) challenge },
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/SzegedyIV16},
  eprint        = {1602.07261},
  groups        = {ResNet CNN allgemein},
  timestamp     = {Wed, 07 Jun 2017 14:42:58 +0200},
  url           = {http://arxiv.org/abs/1602.07261},
}

@Article{Nguyen2014,
  author        = {Anh Mai Nguyen and Jason Yosinski and Jeff Clune},
  title         = {Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images},
  journal       = {CoRR},
  year          = {2014},
  volume        = {abs/1412.1897},
  abstract      = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call "fooling images" (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision. },
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/NguyenYC14},
  eprint        = {1412.1897},
  groups        = {ResNet CNN allgemein},
  timestamp     = {Wed, 07 Jun 2017 14:42:29 +0200},
  url           = {http://arxiv.org/abs/1412.1897},
}

@InProceedings{Krizhevsky2012,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
  year      = {2012},
  series    = {NIPS'12},
  pages     = {1097--1105},
  publisher = {Curran Associates Inc.},
  abstract  = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
  acmid     = {2999257},
  groups    = {ResNet CNN allgemein},
  location  = {Lake Tahoe, Nevada},
  numpages  = {9},
  url       = {http://dl.acm.org/citation.cfm?id=2999134.2999257},
}

@Article{hawrylo2018,
  author    = {Paweł Hawryło and Bartłomiej Bednarz and Piotr Wężyk and Marta Szostak},
  title     = {Estimating defoliation of Scots pine stands using machine learning methods and vegetation indices of Sentinel-2},
  journal   = {European Journal of Remote Sensing},
  year      = {2018},
  volume    = {51},
  number    = {1},
  pages     = {194-205},
  abstract  = {In the presented study, the Sentinel-2 vegetation indices (VIs) were evaluated in context of estimating defoliation of Scots pine stands in western Poland. Regression and classification models were built based on reference data from 50 field plots and Sentinel-2 satellite images from three acquisition dates. Three machine-learning (ML) methods were tested: k-nearest neighbors (kNN), random forest (RF), and support vector machines (SVM). Regression models predicted stands defoliation with moderate accuracy. R2 values for regression models amounted to 0.53, 0.57, 0.57 for kNN, RF and SVM, accordingly. Analogically, the following values of normalized root mean squared error were obtained: 12.2%, 11.9% and 11.6%. Overall accuracies for two-class classification models were 78%, 75%, 78% for kNN, RF and SVM methods. The Green Normalized Difference Vegetation Index and MERIS Terrestrial Chlorophyll Index VIs were found to be most robust defoliation predictors regardless of the ML method. We conclude that Sentinel-2 satellite images provide useful information about forest defoliation and may contribute to forest monitoring systems.},
  doi       = {10.1080/22797254.2017.1417745},
  groups    = {Satellite},
  publisher = {Taylor \& Francis},
}

@Article{Marx2017,
  author    = {A Marx and B Kleinschmit},
  title     = {{Sensitivity analysis of RapidEye spectral bands and derived vegetation indices for insect defoliation detection in pure Scots pine stands}},
  journal   = {iForest - Biogeosciences and Forestry},
  year      = {2017},
  number    = {4},
  pages     = {659-668},
  abstract  = {This study investigated the statistical relationship between defoliation in pine forests infested by nun moths (Lymantria monacha) and the spectral bands of the RapidEye sensor, including the derived normalized difference vegetation index (NDVI) and the normalized difference red-edge index (NDRE). The strength of the relationship between the spectral variables and the ground reference samples of percent remaining foliage (PRF) was assessed over three test years by the Spearman},
  doi       = {10.3832/ifor1727-010},
  groups    = {Satellite},
  keywords  = {Forest Health, Discriminant Analysis, Pine Defoliation, Normalized Difference Red-edge Index, Decision Tree Classification},
  posted-at = {2017-07-11},
  vol       = {10},
}

@Article{rullan2013,
  author   = {C.D. Rullan-Silva and A.E. Olthoff and J.A. Delgado de la Mata and J.A. Pajares-Alonso},
  title    = {Remote Monitoring of Forest Insect Defoliation -A Review-},
  journal  = {Forest Systems},
  year     = {2013},
  volume   = {22},
  number   = {3},
  pages    = {377--391},
  issn     = {2171-9845},
  abstract = {Aim of study: This paper reviews the global research during the last 6 years (2007-2012) on the state, trends and potential of remote sensing for detecting, mapping and monitoring forest defoliation caused by insects.Area of study: The review covers research carried out within different countries in Europe and America.Main results: A nation or region wide monitoring system should be scaled in two levels, one using time-series with moderate to coarse resolutions, and the other with fine or high resolution. Thus, MODIS data is increasingly used for early warning detection, whereas Landsat data is predominant in defoliation damage research. Furthermore, ALS data currently stands as the more promising option for operative detection of defoliation.Vegetation indices based on infrared-medium/near-infrared ratios and on moisture content indicators are of great potential for mapping insect pest defoliation, although NDVI is the most widely used and tested.Research highlights: Among most promising methods for insect defoliation monitoring are Spectral Mixture Analysis, best suited for detection due to its sub-pixel recognition enhancing multispectral data, and use of logistic models as function of vegetation index change between two dates, recommended for predicting defoliation.Key words: vegetation damage; pest outbreak; spectral change detection.},
  doi      = {10.5424/fs/2013223-04417},
  groups   = {Satellite},
}

@Article{Zarcotejada2018,
  author   = {P.J. Zarco-Tejada and A. Hornero and R. Hernández-Clemente and P.S.A. Beck},
  title    = {Understanding the temporal dimension of the red-edge spectral region for forest decline detection using high-resolution hyperspectral and Sentinel-2a imagery},
  journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  year     = {2018},
  volume   = {137},
  pages    = {134 - 148},
  issn     = {0924-2716},
  abstract = {The operational monitoring of forest decline requires the development of remote sensing methods that are sensitive to the spatiotemporal variations of pigment degradation and canopy defoliation. In this context, the red-edge spectral region (RESR) was proposed in the past due to its combined sensitivity to chlorophyll content and leaf area variation. In this study, the temporal dimension of the RESR was evaluated as a function of forest decline using a radiative transfer method with the PROSPECT and 3D FLIGHT models. These models were used to generate synthetic pine stands simulating decline and recovery processes over time and explore the temporal rate of change of the red-edge chlorophyll index (CI) as compared to the trajectories obtained for the structure-related Normalized Difference Vegetation Index (NDVI). The temporal trend method proposed here consisted of using synthetic spectra to calculate the theoretical boundaries of the subspace for healthy and declining pine trees in the temporal domain, defined by CItime=n/CItime=n+1 vs. NDVItime=n/NDVItime=n+1. Within these boundaries, trees undergoing decline and recovery processes showed different trajectories through this subspace. The method was then validated using three high-resolution airborne hyperspectral images acquired at 40 cm resolution and 260 spectral bands of 6.5 nm full-width half-maximum (FWHM) over a forest with widespread tree decline, along with field-based monitoring of chlorosis and defoliation (i.e., ‘decline’ status) in 663 trees between the years 2015 and 2016. The temporal rate of change of chlorophyll vs. structural indices, based on reflectance spectra extracted from the hyperspectral images, was different for trees undergoing decline, and aligned towards the decline baseline established using the radiative transfer models. By contrast, healthy trees over time aligned towards the theoretically obtained healthy baseline. The applicability of this temporal trend method to the red-edge bands of the MultiSpectral Imager (MSI) instrument on board Sentinel-2a for operational forest status monitoring was also explored by comparing the temporal rate of change of the Sentinel-2-derived CI over areas with declining and healthy trees. Results demonstrated that the Sentinel-2a red-edge region was sensitive to the temporal dimension of forest condition, as the relationships obtained for pixels in healthy condition deviated from those of pixels undergoing decline.},
  doi      = {https://doi.org/10.1016/j.isprsjprs.2018.01.017},
  groups   = {Satellite},
  keywords = {Hyperspectral, Red edge, Forest decline, Chlorophyll, Sentinel-2a, Radiative transfer},
  url      = {http://www.sciencedirect.com/science/article/pii/S0924271618300224},
}

@Article{frampton2013,
  author   = {William James Frampton and Jadunandan Dash and Gary Watmough and Edward James Milton},
  title    = {Evaluating the capabilities of Sentinel-2 for quantitative estimation of biophysical variables in vegetation},
  journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  year     = {2013},
  volume   = {82},
  pages    = {83 - 92},
  issn     = {0924-2716},
  doi      = {https://doi.org/10.1016/j.isprsjprs.2013.04.007},
  groups   = {Satellite},
  keywords = {Vegetation, Sentinel-2, Chlorophyll, Red-Edge, LAI},
  url      = {http://www.sciencedirect.com/science/article/pii/S092427161300107X},
}

@Article{Stone2017,
  author      = {Stone, Christine and Mohammed, Caroline},
  title       = {Application of Remote Sensing Technologies for Assessing Planted Forests Damaged by Insect Pests and Fungal Pathogens: a Review},
  journal     = {Current Forestry Reports},
  year        = {2017},
  volume      = {3},
  number      = {2},
  pages       = {75-92},
  month       = {3},
  note        = {This article is part of the Topical Collection on Remote Sensing},
  abstract    = {Purpose of Review In this review, we highlight recent developments and applications in remote sensing that can improve the accuracy and timeliness of health assessments in plantations managed for timber and pulp production. The detection and mapping of damage extent and severity caused by insect pests and fungal pathogens is a common requirement of foresters managing plantations. The objectives of these surveys can range from early detection for targeted intervention to more strategic aims of predicting stand susceptibility or evaluating the performance of management strategies.   Recent Findings Recent developments in remote sensing technologies and big data modelling techniques can now provide spatially explicit, quantitative solutions for these management objectives that are more accurate than manual field-based assessments of tree damage or airborne visual mapping. Past studies have identified a large number of spectral, textural and structural metrics that have been used in models to classify specific tree crown damage symptoms. This process requires a detailed understanding of the chronology of crown symptoms for specific damaging agents and the spectral responses to these symptoms. Continuing increases in the spatial and spectral resolution of remote sensors enables crown-level damage classification.   Summary The development of data processing workflows that fuse spectral information with three-dimensional (3D) data acquired simultaneously from single or different remote platforms promote the opportunities to derive both structural and physiological crown-level attributes that relate to crown damage. The simultaneous acquisition of spectral and 3D point data will enable plantation foresters to derive several spatial products, including the assessment of tree health in a cost-effective manner.},
  affiliation = {NSW Forest Science, NSW Department of Industry – Lands; School of Land and Food, University of Tasmania},
  copyright   = {Her Majesty the Queen in Right of Australia as represented by the State Government of NSW},
  doi         = {10.1007/s40725-017-0056-1},
  groups      = {Satellite},
  keywords    = {Remote sensing; Plantation health; Damage; Insect pests; Fungal pathogens; Diseases},
  language    = {English},
}

@Book{chollet2017,
  title     = {Deep Learning with Python},
  publisher = {Manning Publications Company},
  year      = {2017},
  author    = {Chollet, F.},
  isbn      = {9781617294433},
  groups    = {ResNet CNN allgemein},
}

@Article{Goodfellow2014,
  author        = {Ian J. Goodfellow and Jean Pouget{-}Abadie and Mehdi Mirza and Bing Xu and David Warde{-}Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
  title         = {Generative Adversarial Networks},
  journal       = {CoRR},
  year          = {2014},
  volume        = {abs/1406.2661},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/GoodfellowPMXWOCB14},
  eprint        = {1406.2661},
  groups        = {GAN VAE Dataaugmentation},
  timestamp     = {Wed, 07 Jun 2017 01:00:00 +0200},
  url           = {http://arxiv.org/abs/1406.2661},
}

@Article{Inoue2018,
  author        = {Hiroshi Inoue},
  title         = {Data Augmentation by Pairing Samples for Images Classification},
  journal       = {CoRR},
  year          = {2018},
  volume        = {abs/1801.02929},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1801-02929},
  eprint        = {1801.02929},
  groups        = {GAN VAE Dataaugmentation},
  timestamp     = {Thu, 01 Feb 2018 19:52:26 +0100},
  url           = {http://arxiv.org/abs/1801.02929},
}

@Article{Perez2017,
  author        = {Luis Perez and Jason Wang},
  title         = {The Effectiveness of Data Augmentation in Image Classification using Deep Learning},
  journal       = {CoRR},
  year          = {2017},
  volume        = {abs/1712.04621},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1712-04621},
  eprint        = {1712.04621},
  groups        = {GAN VAE Dataaugmentation},
  timestamp     = {Wed, 03 Jan 2018 12:33:17 +0100},
  url           = {http://arxiv.org/abs/1712.04621},
}

@TechReport{Sanasilva1990,
  author = {BUWAL/Eidgenössische Forstdirektion, Eidgenössische Forschungsanstalt für Wald, Schnee und Landschaft WSL},
  title  = {Sanasilva-Waldschadenbericht 1990},
  year   = {1990},
  groups = {Forest and Trees},
}

@TechReport{30yearsICP2016,
  author      = {T.G.M. Sanders and A.K. Michel and M. Ferretti},
  title       = {30 years of monitoring the effects of long-range transboundary air pollution on forests in Europe and beyond},
  institution = {UNECE/ICP Forests},
  year        = {2016},
  address     = {Eberswalde},
  groups      = {Forest and Trees},
}

@MastersThesis{Lang2017,
  author = {Nico Lang},
  title  = {Deep learning and Google Maps for tree monitoring},
  school = {ETH Zürich},
  year   = {2017},
  groups = {Related Work Trees},
}

@Article{Shendryk2016,
  author    = {Iurii Shendryk and Mark Broich and Mirela G. Tulbure and Andrew McGrath and David Keith and Sergey V. Alexandrov},
  title     = {Mapping individual tree health using full-waveform airborne laser scans and imaging spectroscopy: A case study for a floodplain eucalypt forest},
  journal   = {Remote Sensing of Environment},
  year      = {2016},
  volume    = {187},
  pages     = {202-217},
  booktitle = {Remote Sensing of Environment},
  doi       = {10.1016/j.rse.2016.10.014},
  groups    = {Forest and Trees},
  publisher = {Elsevier {BV}},
}

@Article{ulrich1980,
  author  = {B. Ulrich and R. Mayer and P.K. Khanna},
  title   = {Chemical changes due to acid precipitation in a loess-derived soil in central Europe},
  journal = {Soil Sci. 130},
  year    = {1980},
  pages   = {193-199},
  groups  = {Forest and Trees},
}

@Article{borianne2017,
  author   = {Philippe Borianne and Gérard Subsol and Yves Caraglio},
  title    = {Automated efficient computation of crown transparency from tree silhouette images},
  journal  = {Computers and Electronics in Agriculture},
  year     = {2017},
  volume   = {133},
  pages    = {108 - 118},
  issn     = {0168-1699},
  abstract = {The transparency of trees is the most important indicator for a forest health assessment. This paper presents an efficient method for calculating the crown transparency coefficient from tree binary images. This coefficient is based on the automated quantification of the deep indentation, macro-hole and micro-hole densities. Circular structuring elements are introduced, among other things, to automatically find the significant biological size. The symmetric tree convex hull and the tree smoothed contour are defined to delineate the reference areas necessary to evaluate the above-mentioned densities. Statistical thresholds are proposed to eliminate human operator subjectivity, especially in the automated identification of anatomical elements such as soft and deep crown-indentations or macro and micro crown-holes. A point-wise transparency map is produced to better appreciate the origin of the visible skylight areas in the crown. The crown micro-hole density is calculated from the 0.1-to-0.5 transparency points, the crown macro-hole density from the 0.5-to-1 transparency points. We finally opt for weighting of the above three densities with regard to the importance of the symptoms they describe for a more relevant crown transparency coefficient. A comparative study on several trees from full-size and half-size binary images showed that our method is similar overall to the DSO and less sensitive to scale reduction.},
  doi      = {https://doi.org/10.1016/j.compag.2016.12.011},
  groups   = {Forest and Trees},
  keywords = {Tree crown, Foliage transparency, Tree binary image, Deep crown-indentation density},
}

@Article{lee1983,
  author  = {Y. Jim Lee and Rene I. Alfaro and G. A. Van Sickle},
  title   = {Tree-crown defoliation measurement from digitized photographs},
  journal = {Canadian Journal of Forest Research},
  year    = {1983},
  volume  = {13},
  number  = {5},
  pages   = {956-961},
  doi     = {10.1139/x83-127},
  groups  = {Forest and Trees},
}

@TechReport{meining2016,
  author    = {Stefan Meining and Yvonne Morgenstern and Nicole Wellbrock and Nadine Eickenscheidt},
  title     = {Results of the European Photo International Cross-comparison Course as part of the quality assurance of the crown condition assessment 2015 (Photo ICC 2015)},
  year      = {2016},
  type      = {Th\"{u}nen Working Paper},
  number    = {61},
  note      = {urn:nbn:de:gbv:253-201607-dn057012-8},
  abstract  = {Photo ICCs represent one of different measures for quality assurance of the crown condition survey, which is part of the European forest monitoring. The European Photo ICC 2015 took place between June 23rd and September 29th and was carried out for the three regions Northern, Central and Mediterranean Europe. In total 123 teams participated. The defoliation and assessable crown were assessed on the basis of photos for all main tree species of one region. Half of the photos had already been used at the Photo ICC 2010. The mean deviation of the countries from the weighted median of all countries of one region was evaluated as well as the occurrence of outliers and the specification of the assessable crown. The repeatedly used photos further enabled the evaluation of the assessment continuity. The results reveal a good homogeneity of the defoliation assessment within Europe. The mean deviation of the countries usually lay within a ±10%-interval and most countries only showed few outliers. For some regions and tree species, however, systematic differences in the defoliation assessment among countries were observed. Countries participating in the Photo ICC for two regions, in general displayed the same trend for both regions. Differences in the definition of the assessable crown did not result in larger deviations regarding the defoliation assessment. In Central Europe, the defoliation of beech (Fagus sylvatica) and oak (Quercus robur und Q. petraea) was significantly higher for the same photos in 2015 than in 2010. This observation existed for almost all participating countries. Several reasons for this increase are possible like differences in the quality of the printed photos or varying experience of teams in the defoliation assessment. No significant differences between 2010 and 2015 were found for the investigated tree species of Northern and Mediterranean Europe as well as for the coniferous tree species of Central Europe. The results of the Photo ICC 2015 underline the need to carry out photo courses as regular quality assurance in the crown condition survey. The advantages include the reproducibility of results, the option of testing the continuity of assessment, participation of a larger number of teams and saving of costs and time. Thus, Photo ICCs represent a useful addition to nation-wide and European-wide Field ICCs to ensure data quality in the crown condition survey. --  -- Photo-ICCs stellen eine von verschiedenen Ma\ss{}nahmen zur Qualit\"{a}tssicherung der Kronenzustandsansprache im Rahmen des europaweit stattfindenden Forstlichen Umweltmonitorings dar. Der europ\"{a}ische Photo-ICC 2015 wurde im Zeitraum vom 23.06. bis 29.09.2015 f\"{u}r die drei Regionen Nord-, Mittel- und S\"{u}deuropa durchgef\"{u}hrt. Insgesamt haben 123 Teams an dem Photo-ICC 2015 teilgenommen. Anhand von Fotos wurden die Kronenverlichtung und der Boniturbereich der jeweiligen Hauptbaumarten einer Region bestimmt. Die H\"{a}lfte der Fotos fand bereits im Photo-ICC 2010 Verwendung. Bewertet wurde die mittlere Abweichung der L\"{a}nder vom gewichteten Median aller L\"{a}nder einer Region, das Vorkommen von Ausrei\ss{}ern sowie die Wahl des Boniturbereichs. Die Wiederholungsfotos erm\"{o}glichten au\ss{}erdem eine Aussage \"{u}ber die Sch\"{a}tzkontinuit\"{a}t. Die Ergebnisse belegen insgesamt eine gute Homogenit\"{a}t der Kronenzustandsansprache innerhalb Europas. Die mittleren Abweichungen bewegten sich i.d.R. im ±10%-Abweichungsbereich und die meisten L\"{a}nder wiesen nur wenige Ausrei\ss{}er auf. Allerdings konnten auch systematische Abweichungen einzelner L\"{a}nder beobachtet werden. L\"{a}nder die am Photo-ICC f\"{u}r zwei Regionen teilgenommen haben, zeigten meist den gleichen Trend f\"{u}r beide Regionen. Die unterschiedliche Definition des Boniturbereichs f\"{u}hrte nicht zu deutlichen \"{A}nderungen in der Bewertung der Kronenverlichtung. In Mitteleuropa wurde die Kronenverlichtung der Buche (Fagus sylvatica) und Eiche (Quercus robur und Q. petraea) f\"{u}r dieselben Fotos und f\"{u}r fast jedes teilnehmende Land 2015 signifikant h\"{o}her eingesch\"{a}tzt als 2010. Diese Beobachtung kann verschiedene Gr\"{u}nde haben z.B. Unterschiede in der Druckbildqualit\"{a}t oder unterschiedliche Erfahrung in der Ansprache der Teams. F\"{u}r die betrachteten Baumarten Nord- und S\"{u}deuropas sowie f\"{u}r die Nadelb\"{a}ume Mitteleuropas wurden keine signifikante Abweichung in der Bewertung gefunden. Die Ergebnisse des Photo-ICC 2015 unterstreichen die Notwendigkeit, Photo-ICCs als regelm\"{a}\ss{}ige Qualit\"{a}tssicherungsma\ss{}nahme in der Kronenzustandsaufnahme durchzuf\"{u}hren. Photo-ICCs sind durch die Reproduzierbarkeit der Ergebnisse, durch die \"{U}berpr\"{u}fung der Sch\"{a}tzkontinuit\"{a}t und durch die hohe Erreichbarkeit teilnehmender Aufnahmeteams in Erg\"{a}nzung zu den Feld-Schulungen auf Landes- und Europaebene eine sinnvolle Erg\"{a}nzung zur Sicherung der Datenqualit\"{a}t in der Kronenzustandserhebung.},
  copyright = {http://www.econstor.eu/dspace/Nutzungsbedingungen},
  doi       = {10.3220/WP1469775066000},
  groups    = {Forest and Trees},
  keywords  = {630; defoliation; crown condition survey; forest monitoring; quality assurance; international cross-comparison course; Kronenverlichtung; Kronenzustandserhebung; Forstliches Umweltmonitoring; Qualit\"{a}tssicherung; internationaler Foto-Vergleichskurs},
  language  = {eng},
  publisher = {Johann Heinrich von Th\"{u}nen-Institut},
  url       = {http://hdl.handle.net/10419/145313},
}

@Article{mizoue2002,
  author  = {Nobuya Mizoue},
  title   = {CROCO : Semi-automatic Image Analysis System for Crown Condition Assessment in Forest Health Monitoring},
  journal = {Journal of Forest Planning},
  year    = {2002},
  volume  = {8},
  number  = {1},
  pages   = {17-24},
  doi     = {10.20659/jfp.8.1_17},
  groups  = {Forest and Trees},
}

@Article{huang2016,
  author        = {Gao Huang and Zhuang Liu and Kilian Q. Weinberger},
  title         = {Densely Connected Convolutional Networks},
  journal       = {CoRR},
  year          = {2016},
  volume        = {abs/1608.06993},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/HuangLW16a},
  eprint        = {1608.06993},
  timestamp     = {Wed, 07 Jun 2017 14:42:40 +0200},
  url           = {http://arxiv.org/abs/1608.06993},
}

@Article{gatys2015,
  author        = {Leon A. Gatys and Alexander S. Ecker and Matthias Bethge},
  title         = {A Neural Algorithm of Artistic Style},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1508.06576},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/GatysEB15a},
  eprint        = {1508.06576},
  timestamp     = {Wed, 07 Jun 2017 14:41:58 +0200},
  url           = {http://arxiv.org/abs/1508.06576},
}

@Article{jimenez2014,
  author        = {Danilo Jimenez Rezende and Shakir Mohamed and Daan Wierstra},
  title         = {Stochastic Back-propagation and Variational Inference in Deep Latent Gaussian Models},
  journal       = {CoRR},
  year          = {2014},
  volume        = {abs/1401.4082},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/RezendeMW14},
  eprint        = {1401.4082},
  timestamp     = {Wed, 07 Jun 2017 14:41:28 +0200},
  url           = {http://arxiv.org/abs/1401.4082},
}

@Article{ioffe2015,
  author        = {Sergey Ioffe and Christian Szegedy},
  title         = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1502.03167},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/IoffeS15},
  eprint        = {1502.03167},
  timestamp     = {Wed, 07 Jun 2017 14:40:49 +0200},
  url           = {http://arxiv.org/abs/1502.03167},
}

@Article{srivastava2014,
  author     = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  title      = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal    = {J. Mach. Learn. Res.},
  year       = {2014},
  volume     = {15},
  number     = {1},
  pages      = {1929--1958},
  month      = jan,
  issn       = {1532-4435},
  acmid      = {2670313},
  issue_date = {January 2014},
  keywords   = {deep learning, model combination, neural networks, regularization},
  numpages   = {30},
  publisher  = {JMLR.org},
  url        = {http://dl.acm.org/citation.cfm?id=2627435.2670313},
}

@Article{kingma2013,
  author        = {Diederik P. Kingma and Max Welling},
  title         = {Auto-Encoding Variational Bayes},
  journal       = {CoRR},
  year          = {2013},
  volume        = {abs/1312.6114},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/KingmaW13},
  eprint        = {1312.6114},
  timestamp     = {Wed, 07 Jun 2017 14:40:08 +0200},
  url           = {http://arxiv.org/abs/1312.6114},
}

@TechReport{ICC2006,
  author      = {V. Mues},
  title       = {Results of the International Cross-Comparison Courses 2005},
  institution = {Federal Research Centre for Forestry and Forest Products},
  year        = {2006},
  url         = {https://www.icp-forests.org/pdf/ICC2005.pdf},
}

@Article{reitberger2009,
  author   = {J. Reitberger and Cl. Schnörr and P. Krzystek and U. Stilla},
  title    = {3D segmentation of single trees exploiting full waveform LIDAR data},
  journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  year     = {2009},
  volume   = {64},
  number   = {6},
  pages    = {561 - 574},
  issn     = {0924-2716},
  abstract = {This paper highlights a novel segmentation approach for single trees from LIDAR data and compares the results acquired both from first/last pulse and full waveform data. In a first step, a conventional watershed-based segmentation procedure is set up, which robustly interpolates the canopy height model from the LIDAR data and identifies possible stem positions of the tallest trees in the segments calculated from the local maxima of the canopy height model. Secondly, this segmentation approach is combined with a special stem detection method. Stem positions in the segments of the watershed segmentation are detected by hierarchically clustering points below the crown base height and reconstructing the stems with a robust RANSAC-based estimation of the stem points. Finally, a new three-dimensional (3D) segmentation of single trees is implemented using normalized cut segmentation. This tackles the problem of segmenting small trees below the canopy height model. The key idea is to subdivide the tree area in a voxel space and to set up a bipartite graph which is formed by the voxels and similarity measures between the voxels. Normalized cut segmentation divides the graph hierarchically into segments which have a minimum similarity with each other and whose members (= voxels) have a maximum similarity. The solution is found by solving a corresponding generalized eigenvalue problem and an appropriate binarization of the solution vector. Experiments were conducted in the Bavarian Forest National Park with conventional first/last pulse data and full waveform LIDAR data. The first/last pulse data were collected in a flight with the Falcon II system from TopoSys in a leaf-on situation at a point density of 10 points/m2. Full waveform data were captured with the Riegl LMS-Q560 scanner at a point density of 25 points/m2 (leaf-off and leaf-on) and at a point density of 10 points/m2 (leaf-on). The study results prove that the new 3D segmentation approach is capable of detecting small trees in the lower forest layer. So far, this has been practically impossible if tree segmentation techniques based on the canopy height model were applied to LIDAR data. Compared to a standard watershed segmentation procedure, the combination of the stem detection method and normalized cut segmentation leads to the best segmentation results and is superior in the best case by 12%. Moreover, the experiments show clearly that using full waveform data is superior to using first/last pulse data.},
  doi      = {https://doi.org/10.1016/j.isprsjprs.2009.04.002},
  keywords = {LIDAR, Segmentation, Aerial survey, Clustering, Forestry},
}

@Article{zhang2014,
  author   = {Junjie Zhang and Gunho Sohn and Mathieu Brédif},
  title    = {A hybrid framework for single tree detection from airborne laser scanning data: A case study in temperate mature coniferous forests in Ontario, Canada},
  journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  year     = {2014},
  volume   = {98},
  pages    = {44 - 57},
  issn     = {0924-2716},
  doi      = {https://doi.org/10.1016/j.isprsjprs.2014.08.007},
  keywords = {LiDAR, Forestry, Single tree detection, Local maxima filtering, Marker-controlled watershed segmentation, Stochastic model, Energy minimization, MCMC},
}

@Article{lecunn1998,
  author   = {Y. Lecun and L. Bottou and Y. Bengio and P. Haffner},
  title    = {Gradient-based learning applied to document recognition},
  journal  = {Proceedings of the IEEE},
  year     = {1998},
  volume   = {86},
  number   = {11},
  pages    = {2278-2324},
  month    = {11},
  issn     = {0018-9219},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
  doi      = {10.1109/5.726791},
  keywords = {backpropagation;convolution;multilayer perceptrons;optical character recognition;2D shape variability;GTN;back-propagation;cheque reading;complex decision surface synthesis;convolutional neural network character recognizers;document recognition;document recognition systems;field extraction;gradient based learning technique;gradient-based learning;graph transformer networks;handwritten character recognition;handwritten digit recognition task;high-dimensional patterns;language modeling;multilayer neural networks;multimodule systems;performance measure minimization;segmentation recognition;Character recognition;Feature extraction;Hidden Markov models;Machine learning;Multi-layer neural network;Neural networks;Optical character recognition software;Optical computing;Pattern recognition;Principal component analysis},
}

@Article{Rosenblatt1958,
  author  = {F. Rosenblatt},
  title   = {The Perceptron: A Probabilistic Model for Information Storage and Organization in The Brain},
  journal = {Psychological Review},
  year    = {1958},
  pages   = {65--386},
}

@Article{Szegedy2014,
  author        = {Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott E. Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
  title         = {Going Deeper with Convolutions},
  journal       = {CoRR},
  year          = {2014},
  volume        = {abs/1409.4842},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/SzegedyLJSRAEVR14},
  eprint        = {1409.4842},
  timestamp     = {Wed, 07 Jun 2017 14:40:42 +0200},
  url           = {http://arxiv.org/abs/1409.4842},
}

@Article{Reinhard2001,
  author     = {Reinhard, Erik and Ashikhmin, Michael and Gooch, Bruce and Shirley, Peter},
  title      = {Color Transfer Between Images},
  journal    = {IEEE Comput. Graph. Appl.},
  year       = {2001},
  volume     = {21},
  number     = {5},
  pages      = {34--41},
  month      = sep,
  issn       = {0272-1716},
  acmid      = {618848},
  address    = {Los Alamitos, CA, USA},
  doi        = {10.1109/38.946629},
  issue_date = {September 2001},
  numpages   = {8},
  publisher  = {IEEE Computer Society Press},
  url        = {http://dx.doi.org/10.1109/38.946629},
}

@Article{Zhu2017,
  author        = {Jun{-}Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
  title         = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
  journal       = {CoRR},
  year          = {2017},
  volume        = {abs/1703.10593},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/ZhuPIE17},
  eprint        = {1703.10593},
  timestamp     = {Wed, 07 Jun 2017 14:40:17 +0200},
  url           = {http://arxiv.org/abs/1703.10593},
}

@Article{Isola2016,
  author        = {Phillip Isola and Jun{-}Yan Zhu and Tinghui Zhou and Alexei A. Efros},
  title         = {Image-to-Image Translation with Conditional Adversarial Networks},
  journal       = {CoRR},
  year          = {2016},
  volume        = {abs/1611.07004},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/IsolaZZE16},
  eprint        = {1611.07004},
  timestamp     = {Wed, 07 Jun 2017 14:41:37 +0200},
  url           = {http://arxiv.org/abs/1611.07004},
}

@Article{Girshick2013,
  author        = {Ross B. Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik},
  title         = {Rich feature hierarchies for accurate object detection and semantic segmentation},
  journal       = {CoRR},
  year          = {2013},
  volume        = {abs/1311.2524},
  abstract      = {R-CNN},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/GirshickDDM13},
  eprint        = {1311.2524},
  timestamp     = {Wed, 07 Jun 2017 14:43:00 +0200},
  url           = {http://arxiv.org/abs/1311.2524},
}

@Article{Girshick2015,
  author        = {Ross B. Girshick},
  title         = {Fast {R-CNN}},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1504.08083},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/Girshick15},
  eprint        = {1504.08083},
  timestamp     = {Wed, 07 Jun 2017 14:40:36 +0200},
  url           = {http://arxiv.org/abs/1504.08083},
}

@Article{Ren2015,
  author        = {Shaoqing Ren and Kaiming He and Ross B. Girshick and Jian Sun},
  title         = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal Networks},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1506.01497},
  abstract      = {Faster R-CNN},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/RenHG015},
  eprint        = {1506.01497},
  timestamp     = {Wed, 07 Jun 2017 14:42:40 +0200},
  url           = {http://arxiv.org/abs/1506.01497},
}

@Misc{blenderrep2018,
  title     = {Blender Extensions},
  year      = {2018},
  abstract  = {Hale, Andrew and Buchler, Aaron},
  timestamp = {2018-04-13},
  url       = {https://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts/Curve/Sapling_Tree},
}

@Article{Long2014,
  author        = {Jonathan Long and Evan Shelhamer and Trevor Darrell},
  title         = {Fully Convolutional Networks for Semantic Segmentation},
  journal       = {CoRR},
  year          = {2014},
  volume        = {abs/1411.4038},
  abstract      = {segmentation cnn},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/LongSD14},
  eprint        = {1411.4038},
  timestamp     = {Wed, 07 Jun 2017 14:42:28 +0200},
  url           = {http://arxiv.org/abs/1411.4038},
}

@Manual{Aufnahmeanleitung2017,
  title  = {Aufnahmeanleitung Kronenansprachen auf den Sanasilva- und den LWF-Flächen, interne Version V10-16},
  author = {M. Dobbertin and Ch. Hug and A. Schwyzer and S. Borer and H. Schmalz},
  year   = {2017},
  groups = {Related Work Trees, Forest and Trees},
}

@Book{Kronenbilder1986,
  title     = {Sanasilva Kronenbilder},
  publisher = {Eidgenössische Forschungsanstalt für Wald, Schnee und Landschaft},
  year      = {1986},
  author    = {Stierlin, H-R. and Müller, E.},
  address   = {Birmensdorf},
  edition   = {1.Auflage},
  language  = {ger},
}

@Book{Kuster2013,
  title     = {Geschichte des Waldes : von der Urzeit bis zur Gegenwart},
  publisher = {C.H. Beck},
  year      = {2013},
  author    = {Küster, Hansjörg},
  address   = {München},
  edition   = {3. Auflage der broschierten Ausgabe},
  isbn      = {978-3-406-65065-9},
  keywords  = {GESCHICHTE DER FORSTWIRTSCHAFT + GESCHICHTE DER WÄLDER: 630(091)},
  language  = {ger},
}

@Article{Radford2015,
  author        = {Alec Radford and Luke Metz and Soumith Chintala},
  title         = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1511.06434},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/RadfordMC15},
  eprint        = {1511.06434},
  timestamp     = {Wed, 07 Jun 2017 14:40:30 +0200},
  url           = {http://arxiv.org/abs/1511.06434},
}

@Article{Kingma2014,
  author        = {Diederik P. Kingma and Jimmy Ba},
  title         = {Adam: {A} Method for Stochastic Optimization},
  journal       = {CoRR},
  year          = {2014},
  volume        = {abs/1412.6980},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/KingmaB14},
  eprint        = {1412.6980},
  timestamp     = {Wed, 07 Jun 2017 14:40:52 +0200},
  url           = {http://arxiv.org/abs/1412.6980},
}

@Article{Duchi2011,
  author     = {Duchi, John and Hazan, Elad and Singer, Yoram},
  title      = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal    = {J. Mach. Learn. Res.},
  year       = {2011},
  volume     = {12},
  pages      = {2121--2159},
  issn       = {1532-4435},
  acmid      = {2021068},
  issue_date = {2/1/2011},
  numpages   = {39},
  publisher  = {JMLR.org},
  url        = {http://dl.acm.org/citation.cfm?id=1953048.2021068},
}

@Misc{Hardik2018,
  author       = {Bansal, Hardik and Rathore, Archit},
  title        = {CycleGAN},
  howpublished = {Github},
  year         = {2018},
  timestamp    = {2018-05-03},
  url          = {https://github.com/hardikbansal/CycleGAN},
}

@Article{Richter2016,
  author        = {Stephan R. Richter and Vibhav Vineet and Stefan Roth and Vladlen Koltun},
  title         = {Playing for Data: Ground Truth from Computer Games},
  journal       = {CoRR},
  year          = {2016},
  volume        = {abs/1608.02192},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/RichterVRK16},
  eprint        = {1608.02192},
  timestamp     = {Thu, 14 Dec 2017 17:11:48 +0100},
  url           = {http://arxiv.org/abs/1608.02192},
}

@Misc{blender2018,
  title       = {Blender},
  year        = {2018},
  institution = {Blender Foundation},
  timestamp   = {2018-06-11},
  url         = {https://www.blender.org/},
}

@Misc{HDRIhaven,
  author    = {Greg Zaal},
  title     = {HDRIhaven},
  year      = {2018},
  timestamp = {2018-05-30},
  url       = {https://hdrihaven.com},
}

@Manual{Baumann2016,
  title     = {Building Trees with Blender V2.0},
  author    = {Peter Baumann},
  month     = {03},
  year      = {2016},
  timestamp = {2018-04-10},
  url       = {http://www.mediafire.com/file/19unz3nmvmq4m61/BuildingTreesWithBlender_V2.0.pdf},
}

@Misc{Bansal2018,
  author       = {Bansal, Hardik and Rathore, Archit},
  title        = {CycleGAN},
  howpublished = {Github},
  year         = {2018},
  timestamp    = {2018-05-03},
  url          = {https://github.com/hardikbansal/CycleGAN},
}

@Misc{gan2018,
  author    = {Hindupur, Avinash},
  title     = {GANzoo},
  year      = {2018},
  timestamp = {2018-06-05},
  url       = {https://deephunt.in/the-gan-zoo-79597dc8c347},
}

@Misc{karpathy2018,
  author    = {Karpathy, Andrej},
  title     = {CS231n Convolutional Neural Networks for Visual Recognition},
  year      = {2018},
  timestamp = {2018-06-06},
  url       = {http://cs231n.github.io/},
}

@Misc{Hinton20xx,
  author    = {F. Hinton and N. Srivastava and K. Swersky},
  title     = {Neural Networks for Machine Learning - Lecture 6a},
  year      = {2012},
  timestamp = {2018-06-06},
  url       = {https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}
